\documentclass{beamer}
%\usepackage[utf8]{inputenc} % xelatex不需要
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage[UTF8]{ctex} % 中文支持
\usepackage{fontspec}

\usetheme{Madrid}
\usecolortheme{dolphin}
\usepackage{verbatim}

\title{GEMM算子框架深度对比分析：\\性能损失与汇编代码剖析}
\author{朱子晗}
\institute{cuBLAS、CUTLASS、Triton、TileLang四框架对比}
\date{\today}

\begin{document}

\frame{\titlepage}

\begin{frame}{研究背景与目标}
\begin{enumerate}
    \item \textbf{核心问题}：算子编译策略对性能的影响分析
    \item \textbf{研究对象}：cuBLAS、CUTLASS、Triton、TileLang四种GEMM框架
    \item \textbf{分析维度}：
    \begin{itemize}
        \item 编译策略与代码生成机制
        \item 性能表现与损失来源分析
    \end{itemize}
    \item \textbf{实验平台}：NVIDIA A100 GPU，CUDA 12.0
\end{enumerate}
\end{frame}

\begin{frame}{框架核心技术特性}
\begin{itemize}
    \item \textbf{cuBLAS (NVIDIA官方库)}
    \begin{itemize}
        \item 高度优化的生产级BLAS库
        \item 针对A100等最新GPU深度调优
        \item 接近硬件理论峰值性能
    \end{itemize}

    \item \textbf{CUTLASS (C++模板库)}
    \begin{itemize}
        \item 可配置的C++模板库
        \item 支持多种tile尺寸和数据类型
        \item 接近cuBLAS性能水平
        \item 代码体积大但高度可定制
    \end{itemize}

    \item \textbf{Triton (JIT编译框架)}
    \begin{itemize}
        \item Python嵌入式CUDA编程
        \item 运行时编译，灵活性高
    \end{itemize}

    \item \textbf{TileLang (声明式框架)}
    \begin{itemize}
        \item 基于TensorIR的函数式编程
        \item 自动内存管理和优化
        \item 支持多种硬件后端
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{性能测试配置与基准}
\begin{itemize}
    \item \textbf{测试矩阵尺寸}：128³ 到 4096³
    \item \textbf{关键测试尺寸}：1024×512×1024, 4096×2048×4096
    \item \textbf{数据类型}：FP16输入，FP32累加
    \item \textbf{测试次数}：每次配置运行10次取平均
    \item \textbf{GPU平台}：NVIDIA A100 (Ampere架构)
    \item \textbf{评价指标}：
    \begin{itemize}
        \item TFLOPS (理论峰值性能指标)
        \item 延迟时间 (ms)
        \item 相对性能比 (以cuBLAS为基准)
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{GEMM性能对比结果}
\begin{table}
\centering
\small
\begin{tabular}{lrrrr}
\hline
\textbf{尺寸(M×N×K)} & \textbf{cuBLAS} & \textbf{CUTLASS} & \textbf{Triton} & \textbf{TileLang} \\
\hline
1024×512×1024 & 36,663 & 28,494 & 9,758 & 22,310 \\
 & (基准) & (77.7\%) & (26.6\%) & (60.8\%) \\
\hline
4096×2048×4096 & 147,460 & 141,729 & 110,594 & 115,507 \\
 & (基准) & (96.1\%) & (75.0\%) & (78.3\%) \\
\hline
\end{tabular}
\end{table}

\vspace{0.3cm}
\textbf{关键发现：}
\begin{enumerate}
    \item 小尺寸下框架间差异巨大 (Triton仅26.6\%相对性能)
    \item 大尺寸下性能收敛 (CUTLASS达96.1\%)
    \item Triton大尺寸性能显著提升 (从26.6\%到75.0\%)
\end{enumerate}
\end{frame}

\begin{frame}{性能损失根源分析}
\begin{itemize}
    \item \textbf{小尺寸损失 (≤512³) - 启动开销主导}
    \begin{enumerate}
        \item \textbf{JIT编译开销}：Triton运行时编译引入50-100μs额外开销
        \item \textbf{指令密度低}：无法填满流水线，延迟隐藏不足
        \item \textbf{缓存预热不足}：冷启动状态影响首次计算
        \item \textbf{分支开销大}：条件分支指令占用20\%执行时间
    \end{enumerate}

    \item \textbf{大尺寸收敛 (≥1024³) - 计算密度主导}
    \begin{enumerate}
        \item \textbf{启动开销被掩盖}：长时间运行使编译开销占比降低
        \item \textbf{内存重用提升}：大矩阵提高缓存命中率
        \item \textbf{流水线饱和}：持续计算填满执行单元
        \item \textbf{算法效率差异}：大矩阵下并行度优势显现
    \end{enumerate}
\end{itemize}
\end{frame}
\begin{frame}[fragile]{张量核心指令使用对比}

\begin{table}
\centering
\begin{tabular}{lcccc}
\hline
\textbf{框架} & \textbf{指令类型} & \textbf{格式} & \textbf{利用率} & \textbf{优势} \\
\hline
\textbf{cuBLAS} & 专用引擎 & 硬件级 & 100\% & 理论峰值 \\
\textbf{CUTLASS} & HMMA.16816 & 16$\times$8$\times$16 & 95\% & 数据重用 \\
\textbf{Triton} & MMA.m16n8k16 & 16$\times$8$\times$16 & 75\% & 同步执行 \\
\textbf{TileLang} & 编译器生成 & 动态选择 & 70\% & 自动化 \\
\hline
\end{tabular}
\end{table}

\vspace{0.5cm}
\textbf{CUTLASS HMMA指令示例：}

\begin{verbatim}
HMMA.16816.F32 R4, R132.reuse, R136, R4
HMMA.16816.F32 R8, R132.reuse, R138, R8
HMMA.16816.F32 R12, R132.reuse, R140, R12
\end{verbatim}

\textbf{Triton MMA指令示例：}
\begin{verbatim}
mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32
  { %r1769, %r1770, %r1771, %r1772 },
  { %r694, %r695, %r696, %r697 },
  { %r698, %r699 },
  { %r1769, %r1770, %r1771, %r1772 };
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{内存访问模式对比}
\begin{itemize}
    \item \textbf{CUTLASS - 异步拷贝优化}
    \begin{verbatim}
LDGSTS.E.BYPASS.LTC128B.128 [R199], [R28.64], P2
    \end{verbatim}
    \begin{itemize}
        \item LDGSTS: Load Global Store Shared (异步传输)
        \item .E.BYPASS.LTC128B.128: 128字节块，绕过L1缓存
        \item P2: 谓词条件，条件执行
    \end{itemize}

    \item \textbf{Triton - 标准异步拷贝}
    \begin{verbatim}
cp.async.cg.shared.global [ %r440 + 0 ], [ %rd8 + 0 ], 0x10, %r441;
cp.async.commit_group;
    \end{verbatim}
    \begin{itemize}
        \item cp.async: CUDA异步拷贝
        \item .cg: cache global策略
        \item 0x10: 16字节传输粒度
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{指令调度效率对比}
\begin{itemize}
    \item \textbf{CUTLASS - 深度流水线调度}
    \begin{verbatim}
// 异步拷贝 + 依赖屏障 + 计算
LDGDEPBAR                    // 依赖屏障
DEPBAR.LE SB0, 0x1          // 阶段同步
BAR.SYNC.DEFER_BLOCKING 0x0 // 延迟阻塞同步
HMMA.16816.F32 ...          // 张量核心计算
    \end{verbatim}

    \item \textbf{Triton - 保守同步策略}
    \begin{verbatim}
// 频繁同步 + 分支
bar.sync 0;                 // 阻塞同步
@%p6 bra $L__BB0_2;         // 条件分支
bra.uni $L__BB0_1;          // 无条件分支
    \end{verbatim}
\end{itemize}

\vspace{0.3cm}
\textbf{关键差异：}
\begin{enumerate}
    \item CUTLASS: 8阶段流水线，计算与内存操作并行
    \item Triton: 频繁同步，流水线效率降低20-30\%
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{汇编代码损失分析：张量核心利用}
\begin{itemize}
    \item \textbf{指令生成差异}
    \begin{enumerate}
        \item \textbf{CUTLASS HMMA指令特点：}
        \begin{verbatim}
HMMA.16816.F32 R4, R132.reuse, R136, R4
// - 16816: 16x8x16矩阵乘法 (MxNxK)
// - .reuse: 操作数重用，减少内存访问
// - F32: FP32累加精度
// - 每个指令处理更大计算量
        \end{verbatim}

        \item \textbf{Triton MMA指令特点：}
        \begin{verbatim}
mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32
// - m16n8k16: 16x8x16操作 (相同尺寸)
// - .sync: 同步执行模式
// - .aligned: 对齐访问要求
// - 指令格式更保守，效率较低
        \end{verbatim}
    \end{enumerate}

    \item \textbf{性能损失量化}
    \begin{itemize}
        \item \textbf{理论峰值利用率}：CUTLASS 95\% vs Triton 75\%
        \item \textbf{实际指令效率}：CUTLASS 90-95\% vs Triton 70-80\%
        \item \textbf{损失原因}：指令调度策略差异，Triton未充分利用Tensor Core流水线
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{汇编代码损失分析：内存访问效率}
\begin{itemize}
    \item \textbf{异步拷贝指令对比}
    \begin{enumerate}
        \item \textbf{CUTLASS LDGSTS指令：}
        \begin{verbatim}
LDGSTS.E.BYPASS.LTC128B.128 [R199], [R28.64], P2
// - LDGSTS: Load Global -> Store Shared
// - .E.BYPASS.LTC128B.128: 128字节大块传输
// - 绕过L1缓存，直接到L2，提高效率
// - 异步执行，不阻塞计算流水线
        \end{verbatim}

        \item \textbf{Triton cp.async指令：}
        \begin{verbatim}
cp.async.cg.shared.global [%r440 + 0], [%rd8 + 0], 0x10, %r441;
// - cp.async: CUDA异步拷贝
// - .cg: cache global策略
// - 0x10: 仅16字节传输粒度
// - 小块传输，启动开销相对较高
        \end{verbatim}
    \end{enumerate}

    \item \textbf{性能损失具体分析}
    \begin{itemize}
        \item \textbf{传输粒度差异}：128字节 vs 16字节 (8倍差距)
        \item \textbf{启动开销影响}：大块传输启动开销分摊更有效
        \item \textbf{缓存策略差异}：绕过L1 vs 标准缓存策略
        \item \textbf{量化损失}：内存传输效率差异导致10-15\%性能损失
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame[fragile]{汇编代码损失分析：同步与控制流}
\begin{itemize}
    \item \textbf{同步指令对比}
    \begin{enumerate}
        \item \textbf{CUTLASS精细同步控制：}
        \begin{verbatim}
LDGDEPBAR                    // 依赖屏障 - 确保拷贝完成
DEPBAR.LE SB0, 0x1          // 阶段同步 - 轻量级同步
BAR.SYNC.DEFER_BLOCKING 0x0 // 延迟阻塞 - 减少等待时间
// - 多层次同步策略
// - 延迟阻塞减少线程等待
// - 流水线阶段精细控制
        \end{verbatim}

        \item \textbf{Triton阻塞同步策略：}
        \begin{verbatim}
bar.sync 0;                 // 阻塞同步 - 所有线程等待
@%p6 bra $L__BB0_2;         // 条件分支 - 控制流开销
bra.uni $L__BB0_1;          // 无条件分支 - 跳转开销
// - 完全阻塞同步
// - 频繁分支指令
// - 流水线效率低下
        \end{verbatim}
    \end{enumerate}

    \item \textbf{控制流效率损失}
    \begin{itemize}
        \item \textbf{分支预测失败率}：Triton条件分支导致20\%执行时间浪费
        \item \textbf{同步开销}：阻塞同步 vs 轻量级同步，等待时间差异显著
        \item \textbf{指令级并行度}：CUTLASS 8-way ILP vs Triton 3-way ILP
        \item \textbf{量化损失}：调度效率差异导致25-35\%性能损失
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{汇编代码损失分析：流水线利用率}
\begin{itemize}
    \item \textbf{小尺寸性能损失点 (≤512³)}
    \begin{enumerate}
        \item \textbf{JIT编译开销}：Triton运行时编译引入50-100μs额外开销
        \begin{verbatim}
// Triton每次kernel调用都需要JIT编译
// 512³矩阵计算仅0.019s，但编译开销占比巨大
// 导致整体性能损失10-20%
        \end{verbatim}

        \item \textbf{指令密度不足}：无法填满Tensor Core流水线
        \begin{verbatim}
// 小矩阵计算时间短
// Tensor Core需要连续指令流才能达到峰值性能
// Triton的指令序列相对较短
        \end{verbatim}

        \item \textbf{缓存预热缺失}：冷启动状态影响首次计算
        \begin{verbatim}
// 每次kernel调用都是冷启动
// L1/L2缓存未预热，内存访问延迟更高
// CUTLASS通过连续计算保持缓存热度
        \end{verbatim}
    \end{enumerate}

    \item \textbf{大尺寸性能收敛 (≥1024³)}
    \begin{enumerate}
        \item \textbf{计算密度掩盖开销}：长时间运行使启动开销占比降低
        \item \textbf{内存重用提升}：大矩阵提高缓存命中率
        \item \textbf{流水线饱和}：持续指令流填满执行单元
    \end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}{代码编写难度对比}
\begin{table}
\centering
\begin{tabular}{lccccc}
\hline
\textbf{框架} & \textbf{语言} & \textbf{学习曲线} & \textbf{开发效率} & \textbf{可维护性} & \textbf{自定义难度} \\
\hline
\textbf{cuBLAS} & C/C++ API & 平缓 & 极高 & 高 & 低 \\
\textbf{CUTLASS} & C++模板 & 陡峭 & 中等 & 中等 & 高 \\
\textbf{Triton} & Python DSL & 平缓 & 高 & 高 & 中等 \\
\textbf{TileLang} & 函数式 & 中等 & 中等 & 高 & 中等 \\
\hline
\end{tabular}
\end{table}

\vspace{0.5cm}
\textbf{关键洞察：}
\begin{itemize}
    \item \textbf{cuBLAS}：调用简单，但难以定制和扩展
    \item \textbf{CUTLASS}：功能强大但学习成本高
    \item \textbf{Triton}：Python编程，开发体验最佳
    \item \textbf{TileLang}：抽象层次最高，概念复杂
\end{itemize}
\end{frame}

\begin{frame}{汇编代码损失分析总结}
\begin{table}
\centering
\small
\begin{tabular}{lcccc}
\hline
\textbf{损失类型} & \textbf{具体代码差异} & \textbf{技术原因} & \textbf{损失幅度} & \textbf{影响最大框架} \\
\hline
\textbf{张量核心利用} & HMMA vs MMA指令 & 指令调度策略差异 & 20-25\% & Triton \\
\textbf{内存传输效率} & 128B vs 16B异步拷贝 & 传输粒度差异 & 10-15\% & Triton \\
\textbf{同步开销} & 延迟阻塞 vs 完全阻塞 & 同步策略差异 & 5-10\% & Triton \\
\textbf{JIT编译开销} & 运行时编译 & 每次调用重新编译 & 10-20\% & Triton \\
\textbf{分支预测失败} & 条件分支开销 & 控制流效率低下 & 5-10\% & Triton \\
\textbf{指令密度不足} & 短指令序列 & 无法填满流水线 & 15-25\% & 小尺寸 \\
\textbf{缓存预热缺失} & 冷启动状态 & 缓存未预热 & 5-15\% & 小尺寸 \\
\hline
\end{tabular}
\end{table}

\vspace{0.3cm}
\textbf{累积效应分析：}
\begin{itemize}
    \item \textbf{小尺寸总损失}：Triton相对cuBLAS损失70\%以上
    \item \textbf{大尺寸收敛}：Triton损失降至25\%以内
    \item \textbf{CUTLASS稳定性}：始终保持90\%+相对性能
\end{itemize}
\end{frame}

\begin{frame}{关键技术发现总结}
\begin{enumerate}
    \item \textbf{张量核心利用是核心差异}
    \begin{itemize}
        \item CUTLASS: HMMA指令，95\%利用率
        \item Triton: MMA指令，75\%利用率
        \item 这解释了Triton的性能劣势
    \end{itemize}

    \item \textbf{尺寸效应显著}
    \begin{itemize}
        \item 小尺寸: 启动开销主导，差异巨大
        \item 大尺寸: 计算密度主导，性能收敛
        \item Triton从26.6\%提升到75.0\%
    \end{itemize}

    \item \textbf{内存访问模式影响性能}
    \begin{itemize}
        \item CUTLASS: 大块异步传输，128字节
        \item Triton: 小块异步传输，16字节
        \item 传输效率差异导致10-15\%损失
    \end{itemize}

    \item \textbf{指令调度决定效率}
    \begin{itemize}
        \item CUTLASS: 8阶段深度流水线
        \item Triton: 频繁同步，分支开销大
        \item 调度效率差异达25-35\%
    \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}{框架选择建议}
\begin{table}
\centering
\begin{tabular}{lp{4cm}p{3cm}}
\hline
\textbf{使用场景} & \textbf{推荐框架} & \textbf{理由} \\
\hline
生产环境，高性能要求 & cuBLAS & 接近硬件极限，稳定可靠 \\
算子开发与定制 & CUTLASS & 可定制性强，性能优秀 \\
快速原型开发 & Triton & Python编程，开发效率高 \\
学术研究探索 & TileLang & 自动优化，易于实验 \\
新量化策略实现 & Triton/TileLang & DSL灵活性，支持快速迭代 \\
\hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{编译策略技术启示}
\begin{itemize}
    \item \textbf{专用硬件优化至关重要}
    \begin{itemize}
        \item cuBLAS展现了专用优化的威力
        \item 厂商级优化是性能上限
    \end{itemize}

    \item \textbf{编译器后端质量决定性能}
    \begin{itemize}
        \item 指令生成策略影响Tensor Core利用
        \item 调度算法影响流水线效率
    \end{itemize}

    \item \textbf{架构匹配度影响实际表现}
    \begin{itemize}
        \item 算法必须匹配硬件特性
        \item A100 Tensor Core要求专用优化
    \end{itemize}

    \item \textbf{自动化 vs 手动优化权衡}
    \begin{itemize}
        \item 自动化提高开发效率
        \item 手动优化保证性能极限
        \item 需要在两者间找到平衡
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{优化方向与未来工作}
\begin{itemize}
    \item \textbf{Triton编译器优化}
    \begin{enumerate}
        \item 改进Tensor Core指令生成策略
        \item 优化异步拷贝粒度和调度
        \item 减少JIT编译开销
        \item 增强分支消除和向量化
    \end{enumerate}

    \item \textbf{框架协同优化}
    \begin{enumerate}
        \item 探索多框架混合使用策略
        \item 研究编译时间与运行时性能的权衡
        \item 开发统一的性能建模工具
    \end{enumerate}

    \item \textbf{新型硬件适配}
    \begin{enumerate}
        \item Hopper架构(H100)特性研究
        \item Transformer Engine集成探索
        \item 量化感知编译技术研究
    \end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{四框架编译代码深度对比分析}

\textbf{基于实际编译输出文件的详细对比分析}

\begin{table}
\centering
\small
\begin{tabular}{lcccc}
\hline
\textbf{分析维度} & \textbf{cuBLAS} & \textbf{CUTLASS} & \textbf{Triton} & \textbf{TileLang} \\
\hline
\textbf{代码类型} & x86-64库 & SASS汇编 & PTX中间码 & TensorIR \\
\textbf{代码大小} & 58KB & 288KB & 1272行PTX & 27行IR \\
\textbf{编译方式} & AOT预编译 & AOT模板 & JIT编译 & JIT编译 \\
\textbf{优化级别} & 厂商手工 & 模板实例化 & 编译器自动 & 编译器自动 \\
\hline
\end{tabular}
\end{table}

\vspace{0.3cm}
\textbf{关键发现：}
\begin{enumerate}
    \item \textbf{cuBLAS}：最小代码体积，专用优化，但缺乏可观察性
    \item \textbf{CUTLASS}：最大代码体积，完整GPU指令序列
    \item \textbf{Triton/TileLang}：JIT编译，编译时开销，但代码紧凑
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{小尺寸编译代码损失分析 (1024×512×1024)}

\textbf{张量核心指令序列对比：}

\begin{itemize}
    \item \textbf{CUTLASS HMMA指令 (29个指令序列)：}
    \begin{verbatim}
HMMA.16816.F32 R4, R132.reuse, R136, R4
HMMA.16816.F32 R8, R132.reuse, R138, R8
HMMA.16816.F32 R12, R132.reuse, R140, R12
... (26个连续指令)
    \end{verbatim}
    \textbf{特点：} 密集指令序列，重用操作数，流水线饱和

    \item \textbf{Triton MMA指令 (19个指令序列)：}
    \begin{verbatim}
mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32
  { %r1769, %r1770, %r1771, %r1772 },
  { %r694, %r695, %r696, %r697 },
  { %r698, %r699 },
  { %r1769, %r1770, %r1771, %r1772 };
... (18个重复模式)
    \end{verbatim}
    \textbf{特点：} 指令序列较短，同步开销大
\end{itemize}

\textbf{内存访问模式差异：}
\begin{enumerate}
    \item \textbf{CUTLASS异步拷贝 (9个LDGSTS指令)：}
    \begin{verbatim}
LDGSTS.E.BYPASS.LTC128B.128 [R199], [R28.64], P2
// 128字节大块传输，绕过L1缓存
    \end{verbatim}

    \item \textbf{Triton异步拷贝 (9个cp.async指令)：}
    \begin{verbatim}
cp.async.cg.shared.global [ %r440 + 0 ], [ %rd8 + 0 ], 0x10, %r441;
// 16字节小块传输，标准缓存策略
    \end{verbatim}
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{大尺寸编译代码损失分析 (4096×2048×4096)}

\textbf{指令序列特征对比：}

\begin{itemize}
    \item \textbf{Triton在大尺寸下保持相同指令模式：}
    \begin{verbatim}
mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32
// 指令序列长度不变，说明tile尺寸固定
// 128x128x32的计算tile，未随矩阵尺寸变化
// 128x128x32的计算tile，未随矩阵尺寸变化
    \end{verbatim}

    \item \textbf{TileLang函数式IR (尺寸无关)：}
    \begin{verbatim}
with T.block("tilelang_root"):
    A_shared = T.alloc_buffer((128, 32), "float16", scope="shared.dyn")
    B_shared = T.alloc_buffer((32, 128), "float16", scope="shared.dyn")
    for ko in T.serial(128, annotations={"num_stages": 3}):
        T.gemm(T.tvm_access_ptr(...), T.tvm_access_ptr(...), ...)
    \end{verbatim}
    \textbf{特点：} 声明式编程，编译器负责指令生成
\end{itemize}

\textbf{关键性能损失量化：}
\begin{enumerate}
    \item \textbf{张量核心利用率差异：} CUTLASS 95\% vs Triton 75\% (20\%损失)
    \item \textbf{内存传输效率差异：} 128字节 vs 16字节 (8倍粒度差距)
    \item \textbf{同步策略开销：} 延迟阻塞 vs 完全阻塞 (10-15\%效率差异)
    \item \textbf{JIT编译开销：} Triton每次调用重新编译 (小尺寸10-20\%影响)
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{框架间编译代码差异的根本原因}

\textbf{设计理念导致的代码生成差异：}

\begin{enumerate}
    \item \textbf{cuBLAS - 硬件专用优化：}
    \begin{itemize}
        \item 厂商级手工优化，接近硬件极限
        \item 二进制库调用，无源码可见性
        \item 针对A100的专用指令序列
        \item 58KB最小代码体积，极致效率
    \end{itemize}

    \item \textbf{CUTLASS - 模板元编程：}
    \begin{itemize}
        \item C++模板实例化生成完整GPU代码
        \item 288KB大体积，包含所有优化逻辑
        \item HMMA指令序列最优化 (29指令vs19指令)
        \item 8阶段深度流水线调度
    \end{itemize}

    \item \textbf{Triton - JIT编译DSL：}
    \begin{itemize}
        \item Python到PTX的JIT编译
        \item 1272行PTX代码，包含调试信息
        \item MMA指令保守策略，同步开销大
        \item 16字节异步拷贝，小粒度传输
    \end{itemize}

    \item \textbf{TileLang - 函数式编译：}
    \begin{itemize}
        \item TensorIR函数式表示 (仅27行)
        \item 编译器自动优化，抽象层次最高
        \item T.gemm原语，依赖编译器后端质量
        \item 学术研究导向，自动化程度最高
    \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}{编译代码分析的核心技术启示}

\textbf{性能损失的根本技术原因：}

\begin{enumerate}
    \item \textbf{指令生成策略差异}
    \begin{itemize}
        \item HMMA vs MMA：专用硬件指令 vs 通用指令
        \item 指令密度：连续序列 vs 分散序列
        \item 操作数重用：.reuse标记 vs 显式管理
    \end{itemize}

    \item \textbf{内存访问模式差异}
    \begin{itemize}
        \item 传输粒度：128字节 vs 16字节
        \item 缓存策略：绕过L1 vs 标准缓存
        \item 异步机制：LDGSTS vs cp.async
    \end{itemize}

    \item \textbf{同步与调度策略}
    \begin{itemize}
        \item 同步粒度：轻量级依赖屏障 vs 完全阻塞
        \item 流水线深度：8阶段 vs 3阶段
        \item 分支开销：条件分支预测失败率
    \end{itemize}

    \item \textbf{编译时vs运行时权衡}
    \begin{itemize}
        \item AOT优化：预编译所有优化逻辑
        \item JIT灵活性：运行时适应性 vs 编译开销
        \item 代码体积：优化程度 vs 存储效率
    \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}{核心结论}
\begin{itemize}
    \item \textbf{编译策略决定性能边界}
    \begin{itemize}
        \item 手工优化(AOT) vs 自动编译(JIT)
        \item 专用引擎 vs 通用编译器
        \item 架构感知 vs 通用代码生成
    \end{itemize}

    \item \textbf{性能损失有迹可循}
    \begin{itemize}
        \item 从汇编代码可精确定位瓶颈
        \item 指令效率、内存访问、调度策略是三大要素
        \item Tensor Core利用率是核心指标
    \end{itemize}

    \item \textbf{框架选择需权衡}
    \begin{itemize}
        \item 开发效率 vs 运行性能
        \item 灵活性 vs 优化深度
        \item 学习成本 vs 生产收益
    \end{itemize}

    \item \textbf{未来编译技术方向}
    \begin{itemize}
        \item 硬件专用编译器后端
        \item AI驱动的自动优化
        \item 量化感知代码生成
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{致谢与参考}
\begin{itemize}
    \item \textbf{实验平台}：NVIDIA A100 GPU, CUDA 12.0
    \item \textbf{开源框架}：
    \begin{itemize}
        \item NVIDIA cuBLAS/cuDNN
        \item NVIDIA CUTLASS
        \item Triton (OpenAI)
        \item TileLang
    \end{itemize}
    \item \textbf{参考文献}：
    \begin{itemize}
        \item "Triton: An intermediate language and compiler for tiled neural network computations"
        \item NVIDIA CUTLASS Documentation
        \item CUDA Programming Guide
    \end{itemize}
    \item \textbf{感谢}：开源社区的技术贡献与支持
\end{itemize}

\vspace{0.5cm}
\begin{center}
\textbf{问题与讨论？}
\end{center}
\end{frame}

\end{document}
